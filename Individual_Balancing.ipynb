{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WYDFzihTamd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import argparse\n",
    "class RoadSignClassifier:\n",
    "    def createCNN(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        model.add(Conv2D(8, (5, 5), input_shape=inputShape, activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512, activation=\"relu\"))\n",
    "        model.add(Dense(classes, activation=\"softmax\"))\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "data_path = r\"D:\\TrafficSign\\TSRD\"\n",
    "def load_data(dataset):\n",
    "    images = []\n",
    "    classes = []\n",
    "    rows = pd.read_csv(dataset)\n",
    "    rows = rows.sample(frac=1).reset_index(drop=True)\n",
    "    for i, row in rows.iterrows():\n",
    "        img_class = row[\"ClassId\"]\n",
    "        img_path = row[\"Path\"]\n",
    "        image = os.path.join(data_path, img_path)\n",
    "        image = cv2.imread(image)\n",
    "        image_rs = cv2.resize(image, (32, 32), 3)\n",
    "        R, G, B = cv2.split(image_rs)\n",
    "        img_r = cv2.equalizeHist(R)\n",
    "        img_g = cv2.equalizeHist(G)\n",
    "        img_b = cv2.equalizeHist(B)\n",
    "        new_image = cv2.merge((img_r, img_g, img_b))\n",
    "        if i % 500 == 0:\n",
    "            print(f\"loaded: {i}\")\n",
    "        images.append(new_image)\n",
    "        classes.append(img_class)\n",
    "    X = np.array(images)\n",
    "    y = np.array(classes)\n",
    "    \n",
    "    return (X, y)\n",
    "        \n",
    "data_path = r\"D:\\TrafficSign\\TSRD\"\n",
    "def load_all_data():\n",
    "    train_data = r\"D:\\TrafficSign\\TSRD\\Train.csv\"    \n",
    "    images = []\n",
    "    classes = []\n",
    "    rows = pd.read_csv(train_data)\n",
    "    rows = rows.sample(frac=1).reset_index(drop=True)\n",
    "    for i, row in rows.iterrows():\n",
    "        img_class = row[\"ClassId\"]\n",
    "        img_path = row[\"Path\"]\n",
    "        image = os.path.join(data_path, img_path)\n",
    "        image = cv2.imread(image)\n",
    "        image_rs = cv2.resize(image, (32, 32), 3)\n",
    "        R, G, B = cv2.split(image_rs)\n",
    "        img_r = cv2.equalizeHist(R)\n",
    "        img_g = cv2.equalizeHist(G)\n",
    "        img_b = cv2.equalizeHist(B)\n",
    "        new_image = cv2.merge((img_r, img_g, img_b))\n",
    "        if i % 500 == 0:\n",
    "            print(f\"loaded: {i}\")\n",
    "        images.append(new_image)\n",
    "        classes.append(img_class)        \n",
    "    test_data = r\"D:\\TrafficSign\\TSRD\\Test.csv\"\n",
    "    rows = pd.read_csv(test_data)\n",
    "    rows = rows.sample(frac=1).reset_index(drop=True)\n",
    "    for i, row in rows.iterrows():\n",
    "        img_class = row[\"ClassId\"]\n",
    "        img_path = row[\"Path\"]\n",
    "        image = os.path.join(data_path, img_path)\n",
    "        image = cv2.imread(image)\n",
    "        image_rs = cv2.resize(image, (32, 32), 3)\n",
    "        R, G, B = cv2.split(image_rs)\n",
    "        img_r = cv2.equalizeHist(R)\n",
    "        img_g = cv2.equalizeHist(G)\n",
    "        img_b = cv2.equalizeHist(B)\n",
    "        new_image = cv2.merge((img_r, img_g, img_b))\n",
    "        if i % 500 == 0:\n",
    "            print(f\"loaded: {i}\")\n",
    "        images.append(new_image)\n",
    "        classes.append(img_class)\n",
    "        \n",
    "    X = np.array(images)\n",
    "    y = np.array(classes)\n",
    "    \n",
    "    return (X, y)\n",
    "\n",
    "def data_reallocation(whole_X,whole_Y,num_image_per_label):\n",
    "    num_image_per_label_count = np.array(len(num_image_per_label)*[0])\n",
    "    images_training = []\n",
    "    images_testing = []\n",
    "    label_training = []\n",
    "    label_testing = []\n",
    "    for i in range(len(whole_Y)):\n",
    "        if num_image_per_label_count[whole_Y[i]] < num_image_per_label[whole_Y[i]]:\n",
    "            images_training.append(whole_X[i])\n",
    "            label_training.append(whole_Y[i])\n",
    "            num_image_per_label_count[whole_Y[i]]+=1\n",
    "        else:\n",
    "            images_testing.append(whole_X[i])\n",
    "            label_testing.append(whole_Y[i])            \n",
    "            \n",
    "    \n",
    "    return np.array(images_training),np.array(label_training),np.array(images_testing),np.array(label_testing)\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-m\", \"--model\", default=\"output/trafficsignnet_TSRD.model\", help=\"path to output model\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "#####Run this part for the first time and save the pre-processed data. So you do not have to process it every time\n",
    "# train_data = r\"D:\\TrafficSign\\TSRD\\Train.csv\"\n",
    "# test_data = r\"D:\\TrafficSign\\TSRD\\Test.csv\"\n",
    "# (train_X, train_Y) = load_data(train_data)\n",
    "# (test_X, test_Y) = load_data(test_data)\n",
    "# np.save('TSRD_trainX',train_X)\n",
    "# np.save('TSRD_trainY',train_Y)\n",
    "# np.save('TSRD_testX',test_X)\n",
    "# np.save('TSRD_testY',test_Y)\n",
    "#####\n",
    "\n",
    "(whole_X, whole_Y) = load_all_data()\n",
    "num_labels = len(np.unique(whole_Y))\n",
    "wholeY = to_categorical(whole_Y, num_labels)\n",
    "class_totals = wholeY.sum(axis=0)\n",
    "num_image_per_label = np.round(1994/6164*class_totals)\n",
    "train_X,train_Y,test_X,test_Y = data_reallocation(whole_X,whole_Y,num_image_per_label)\n",
    "np.save('TSRD_trainX_balanced',train_X)\n",
    "np.save('TSRD_trainY_balanced',train_Y)\n",
    "np.save('TSRD_testX_balanced',test_X)\n",
    "np.save('TSRD_testY_balanced',test_Y)\n",
    "\n",
    "# train_X = np.load('TSRD_trainX_balanced.npy', allow_pickle=True)\n",
    "# test_X = np.load('TSRD_testX_balanced.npy', allow_pickle=True)\n",
    "# train_Y = np.load('TSRD_trainY_balanced.npy', allow_pickle=True)\n",
    "# test_Y = np.load('TSRD_testY_balanced.npy', allow_pickle=True)\n",
    "print(\"UPDATE: Normalizing data\")\n",
    "trainX = train_X.astype(\"float32\") / 255.0\n",
    "testX = test_X.astype(\"float32\") / 255.0\n",
    "print(\"UPDATE: One-Hot Encoding data\")\n",
    "num_labels = len(np.unique(train_Y))\n",
    "trainY = to_categorical(train_Y, num_labels)\n",
    "testY = to_categorical(test_Y, num_labels)\n",
    "\n",
    "\n",
    "\n",
    "class_totals = trainY.sum(axis=0)\n",
    "class_weights = class_totals.max() / class_totals\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "data_aug = ImageDataGenerator(\n",
    "rotation_range=10,\n",
    "zoom_range=0.15,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1,\n",
    "shear_range=0.15,\n",
    "horizontal_flip=False,\n",
    "vertical_flip=False)\n",
    "\n",
    "model = RoadSignClassifier.createCNN(width=32, height=32, depth=3, classes=58)\n",
    "optimizer = Adam(learning_rate=learning_rate, decay=learning_rate / (epochs))\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "fit = model.fit(\n",
    "    data_aug.flow(trainX, trainY, batch_size=batch_size), \n",
    "    epochs=epochs,\n",
    "    validation_data=(testX, testY),\n",
    "   # class_weight=class_weight_dict,\n",
    "    verbose=1)\n",
    "\n",
    "acc = fit.history['accuracy']\n",
    "val_acc = fit.history['val_accuracy']\n",
    "\n",
    "loss = fit.history['loss']\n",
    "val_loss = fit.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "# plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "np.save('TSRD_Individual_Learning_China_balanced2', [acc,loss,val_acc,val_loss])\n",
    "# model.save(args[\"model\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Individual_Balancing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
